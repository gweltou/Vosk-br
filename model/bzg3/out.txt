running path.sh
running cmd.sh

===== VALIDATING DATA =====


utils/validate_data_dir.sh: file data/train/utt2spk is not sorted or has duplicates
utils/validate_data_dir.sh: file data/test/utt2spk is not sorted or has duplicates
utils/fix_data_dir.sh: file data/train/utt2spk is not in sorted order or not unique, sorting it
utils/fix_data_dir.sh: file data/train/spk2utt is not in sorted order or not unique, sorting it
utils/fix_data_dir.sh: file data/train/text is not in sorted order or not unique, sorting it
utils/fix_data_dir.sh: file data/train/segments is not in sorted order or not unique, sorting it
utils/fix_data_dir.sh: file data/train/wav.scp is not in sorted order or not unique, sorting it
fix_data_dir.sh: kept all 15740 utterances.
fix_data_dir.sh: old files are kept in data/train/.backup
utils/fix_data_dir.sh: file data/test/utt2spk is not in sorted order or not unique, sorting it
utils/fix_data_dir.sh: file data/test/spk2utt is not in sorted order or not unique, sorting it
utils/fix_data_dir.sh: file data/test/text is not in sorted order or not unique, sorting it
utils/fix_data_dir.sh: file data/test/segments is not in sorted order or not unique, sorting it
fix_data_dir.sh: kept all 118 utterances.
fix_data_dir.sh: old files are kept in data/test/.backup
utils/prepare_lang.sh data/local/dict_nosp <UNK> data/local/lang_tmp_nosp data/lang_nosp
Checking data/local/dict_nosp/silence_phones.txt ...
--> reading data/local/dict_nosp/silence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/silence_phones.txt is OK

Checking data/local/dict_nosp/optional_silence.txt ...
--> reading data/local/dict_nosp/optional_silence.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/optional_silence.txt is OK

Checking data/local/dict_nosp/nonsilence_phones.txt ...
--> reading data/local/dict_nosp/nonsilence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/dict_nosp/lexicon.txt
--> reading data/local/dict_nosp/lexicon.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/lexicon.txt is OK

Checking data/local/dict_nosp/extra_questions.txt ...
--> data/local/dict_nosp/extra_questions.txt is empty (this is OK)
--> SUCCESS [validating dictionary directory data/local/dict_nosp]

**Creating data/local/dict_nosp/lexiconp.txt from data/local/dict_nosp/lexicon.txt
prepare_lang.sh: validating output directory
utils/validate_lang.pl data/lang_nosp
Checking existence of separator file
separator file data/lang_nosp/subword_separator.txt is empty or does not exist, deal in word case.
Checking data/lang_nosp/phones.txt ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang_nosp/phones.txt is OK

Checking words.txt: #0 ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang_nosp/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> found no unexplainable phones in phones.txt

Checking data/lang_nosp/phones/context_indep.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang_nosp/phones/context_indep.txt
--> data/lang_nosp/phones/context_indep.int corresponds to data/lang_nosp/phones/context_indep.txt
--> data/lang_nosp/phones/context_indep.csl corresponds to data/lang_nosp/phones/context_indep.txt
--> data/lang_nosp/phones/context_indep.{txt, int, csl} are OK

Checking data/lang_nosp/phones/nonsilence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 160 entry/entries in data/lang_nosp/phones/nonsilence.txt
--> data/lang_nosp/phones/nonsilence.int corresponds to data/lang_nosp/phones/nonsilence.txt
--> data/lang_nosp/phones/nonsilence.csl corresponds to data/lang_nosp/phones/nonsilence.txt
--> data/lang_nosp/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang_nosp/phones/silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang_nosp/phones/silence.txt
--> data/lang_nosp/phones/silence.int corresponds to data/lang_nosp/phones/silence.txt
--> data/lang_nosp/phones/silence.csl corresponds to data/lang_nosp/phones/silence.txt
--> data/lang_nosp/phones/silence.{txt, int, csl} are OK

Checking data/lang_nosp/phones/optional_silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang_nosp/phones/optional_silence.txt
--> data/lang_nosp/phones/optional_silence.int corresponds to data/lang_nosp/phones/optional_silence.txt
--> data/lang_nosp/phones/optional_silence.csl corresponds to data/lang_nosp/phones/optional_silence.txt
--> data/lang_nosp/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang_nosp/phones/disambig.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 5 entry/entries in data/lang_nosp/phones/disambig.txt
--> data/lang_nosp/phones/disambig.int corresponds to data/lang_nosp/phones/disambig.txt
--> data/lang_nosp/phones/disambig.csl corresponds to data/lang_nosp/phones/disambig.txt
--> data/lang_nosp/phones/disambig.{txt, int, csl} are OK

Checking data/lang_nosp/phones/roots.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang_nosp/phones/roots.txt
--> data/lang_nosp/phones/roots.int corresponds to data/lang_nosp/phones/roots.txt
--> data/lang_nosp/phones/roots.{txt, int} are OK

Checking data/lang_nosp/phones/sets.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang_nosp/phones/sets.txt
--> data/lang_nosp/phones/sets.int corresponds to data/lang_nosp/phones/sets.txt
--> data/lang_nosp/phones/sets.{txt, int} are OK

Checking data/lang_nosp/phones/extra_questions.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 9 entry/entries in data/lang_nosp/phones/extra_questions.txt
--> data/lang_nosp/phones/extra_questions.int corresponds to data/lang_nosp/phones/extra_questions.txt
--> data/lang_nosp/phones/extra_questions.{txt, int} are OK

Checking data/lang_nosp/phones/word_boundary.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 175 entry/entries in data/lang_nosp/phones/word_boundary.txt
--> data/lang_nosp/phones/word_boundary.int corresponds to data/lang_nosp/phones/word_boundary.txt
--> data/lang_nosp/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang_nosp/phones/optional_silence.txt
--> data/lang_nosp/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang_nosp/phones/disambig.txt has "#0" and "#1"
--> data/lang_nosp/phones/disambig.txt is OK

Checking topo ...

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang_nosp/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang_nosp/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang_nosp/phones/word_boundary.txt is OK

Checking word-level disambiguation symbols...
--> data/lang_nosp/phones/wdisambig.txt exists (newer prepare_lang.sh)
Checking word_boundary.int and disambig.int
--> generating a 9 word/subword sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 55 word/subword sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang_nosp/oov.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang_nosp/oov.txt
--> data/lang_nosp/oov.int corresponds to data/lang_nosp/oov.txt
--> data/lang_nosp/oov.{txt, int} are OK

--> data/lang_nosp/L.fst is olabel sorted
--> data/lang_nosp/L_disambig.fst is olabel sorted
--> SUCCESS [validating lang directory data/lang_nosp]
utils/validate_lang.pl data/lang_nosp
Checking existence of separator file
separator file data/lang_nosp/subword_separator.txt is empty or does not exist, deal in word case.
Checking data/lang_nosp/phones.txt ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang_nosp/phones.txt is OK

Checking words.txt: #0 ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang_nosp/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> found no unexplainable phones in phones.txt

Checking data/lang_nosp/phones/context_indep.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang_nosp/phones/context_indep.txt
--> data/lang_nosp/phones/context_indep.int corresponds to data/lang_nosp/phones/context_indep.txt
--> data/lang_nosp/phones/context_indep.csl corresponds to data/lang_nosp/phones/context_indep.txt
--> data/lang_nosp/phones/context_indep.{txt, int, csl} are OK

Checking data/lang_nosp/phones/nonsilence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 160 entry/entries in data/lang_nosp/phones/nonsilence.txt
--> data/lang_nosp/phones/nonsilence.int corresponds to data/lang_nosp/phones/nonsilence.txt
--> data/lang_nosp/phones/nonsilence.csl corresponds to data/lang_nosp/phones/nonsilence.txt
--> data/lang_nosp/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang_nosp/phones/silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang_nosp/phones/silence.txt
--> data/lang_nosp/phones/silence.int corresponds to data/lang_nosp/phones/silence.txt
--> data/lang_nosp/phones/silence.csl corresponds to data/lang_nosp/phones/silence.txt
--> data/lang_nosp/phones/silence.{txt, int, csl} are OK

Checking data/lang_nosp/phones/optional_silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang_nosp/phones/optional_silence.txt
--> data/lang_nosp/phones/optional_silence.int corresponds to data/lang_nosp/phones/optional_silence.txt
--> data/lang_nosp/phones/optional_silence.csl corresponds to data/lang_nosp/phones/optional_silence.txt
--> data/lang_nosp/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang_nosp/phones/disambig.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 5 entry/entries in data/lang_nosp/phones/disambig.txt
--> data/lang_nosp/phones/disambig.int corresponds to data/lang_nosp/phones/disambig.txt
--> data/lang_nosp/phones/disambig.csl corresponds to data/lang_nosp/phones/disambig.txt
--> data/lang_nosp/phones/disambig.{txt, int, csl} are OK

Checking data/lang_nosp/phones/roots.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang_nosp/phones/roots.txt
--> data/lang_nosp/phones/roots.int corresponds to data/lang_nosp/phones/roots.txt
--> data/lang_nosp/phones/roots.{txt, int} are OK

Checking data/lang_nosp/phones/sets.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang_nosp/phones/sets.txt
--> data/lang_nosp/phones/sets.int corresponds to data/lang_nosp/phones/sets.txt
--> data/lang_nosp/phones/sets.{txt, int} are OK

Checking data/lang_nosp/phones/extra_questions.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 9 entry/entries in data/lang_nosp/phones/extra_questions.txt
--> data/lang_nosp/phones/extra_questions.int corresponds to data/lang_nosp/phones/extra_questions.txt
--> data/lang_nosp/phones/extra_questions.{txt, int} are OK

Checking data/lang_nosp/phones/word_boundary.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 175 entry/entries in data/lang_nosp/phones/word_boundary.txt
--> data/lang_nosp/phones/word_boundary.int corresponds to data/lang_nosp/phones/word_boundary.txt
--> data/lang_nosp/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang_nosp/phones/optional_silence.txt
--> data/lang_nosp/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang_nosp/phones/disambig.txt has "#0" and "#1"
--> data/lang_nosp/phones/disambig.txt is OK

Checking topo ...

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang_nosp/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang_nosp/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang_nosp/phones/word_boundary.txt is OK

Checking word-level disambiguation symbols...
--> data/lang_nosp/phones/wdisambig.txt exists (newer prepare_lang.sh)
Checking word_boundary.int and disambig.int
--> generating a 36 word/subword sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 43 word/subword sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang_nosp/oov.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang_nosp/oov.txt
--> data/lang_nosp/oov.int corresponds to data/lang_nosp/oov.txt
--> data/lang_nosp/oov.{txt, int} are OK

--> data/lang_nosp/L.fst is olabel sorted
--> data/lang_nosp/L_disambig.fst is olabel sorted
--> SUCCESS [validating lang directory data/lang_nosp]
Checking data/local/dict_nosp/silence_phones.txt ...
--> reading data/local/dict_nosp/silence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/silence_phones.txt is OK

Checking data/local/dict_nosp/optional_silence.txt ...
--> reading data/local/dict_nosp/optional_silence.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/optional_silence.txt is OK

Checking data/local/dict_nosp/nonsilence_phones.txt ...
--> reading data/local/dict_nosp/nonsilence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/dict_nosp/lexicon.txt
--> reading data/local/dict_nosp/lexicon.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/lexicon.txt is OK

Checking data/local/dict_nosp/lexiconp.txt
--> reading data/local/dict_nosp/lexiconp.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/lexiconp.txt is OK

Checking lexicon pair data/local/dict_nosp/lexicon.txt and data/local/dict_nosp/lexiconp.txt
--> lexicon pair data/local/dict_nosp/lexicon.txt and data/local/dict_nosp/lexiconp.txt match

Checking data/local/dict_nosp/extra_questions.txt ...
--> data/local/dict_nosp/extra_questions.txt is empty (this is OK)
--> SUCCESS [validating dictionary directory data/local/dict_nosp]

done

===== FEATURES EXTRACTION =====

steps/make_mfcc.sh --nj 2 --cmd run.pl --mem 2G data/train exp/make_mfcc/train mfcc
utils/validate_data_dir.sh: Successfully validated data-directory data/train
steps/make_mfcc.sh [info]: segments file exists: using that.
steps/make_mfcc.sh: Succeeded creating MFCC features for train
steps/make_mfcc.sh --nj 2 --cmd run.pl --mem 2G data/test exp/make_mfcc/test mfcc
utils/validate_data_dir.sh: Successfully validated data-directory data/test
steps/make_mfcc.sh [info]: segments file exists: using that.
steps/make_mfcc.sh: Succeeded creating MFCC features for test
steps/compute_cmvn_stats.sh data/train exp/make_mfcc/train mfcc
Succeeded creating CMVN stats for train
steps/compute_cmvn_stats.sh data/test exp/make_mfcc/test mfcc
Succeeded creating CMVN stats for test

===== LANGUAGE MODEL CREATION =====
==== MAKING lm.arpa ====

done

==== MAKING G.fst ====

data/local/tmp/lm.arpa

===== MONO TRAINING =====

steps/train_mono.sh --boost-silence 1.25 --nj 2 --cmd run.pl --mem 2G data/train data/lang_nosp exp/mono
steps/train_mono.sh: Initializing monophone system.
steps/train_mono.sh: Compiling training graphs
steps/train_mono.sh: Aligning data equally (pass 0)
steps/train_mono.sh: Pass 1
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 2
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 3
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 4
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 5
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 6
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 7
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 8
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 9
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 10
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 11
steps/train_mono.sh: Pass 12
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 13
steps/train_mono.sh: Pass 14
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 15
steps/train_mono.sh: Pass 16
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 17
steps/train_mono.sh: Pass 18
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 19
steps/train_mono.sh: Pass 20
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 21
steps/train_mono.sh: Pass 22
steps/train_mono.sh: Pass 23
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 24
steps/train_mono.sh: Pass 25
steps/train_mono.sh: Pass 26
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 27
steps/train_mono.sh: Pass 28
steps/train_mono.sh: Pass 29
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 30
steps/train_mono.sh: Pass 31
steps/train_mono.sh: Pass 32
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 33
steps/train_mono.sh: Pass 34
steps/train_mono.sh: Pass 35
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 36
steps/train_mono.sh: Pass 37
steps/train_mono.sh: Pass 38
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 39
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang_nosp exp/mono
steps/diagnostic/analyze_alignments.sh: see stats in exp/mono/log/analyze_alignments.log
11866 warnings in exp/mono/log/align.*.*.log
763 warnings in exp/mono/log/acc.*.*.log
200 warnings in exp/mono/log/update.*.log
exp/mono: nj=2 align prob=-99.00 over 15.31h [retry=0.4%, fail=0.0%] states=135 gauss=977
steps/train_mono.sh: Done training monophone system in exp/mono

===== MONO DECODING =====

WARNING: the --mono, --left-biphone and --quinphone options are now deprecated and ignored.
-0.0435718 -0.044485
[info]: LG not stochastic.
-0.0435718 -0.044485
[info]: CLG not stochastic.
9.18147e-05 -0.0871479
HCLGa is not stochastic

===== MONO ALIGNMENT =====

steps/align_si.sh --boost-silence 1.25 --nj 2 --cmd run.pl --mem 2G data/train data/lang_nosp exp/mono exp/mono_ali_train
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train using model from exp/mono, putting alignments in exp/mono_ali_train
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang_nosp exp/mono_ali_train
steps/diagnostic/analyze_alignments.sh: see stats in exp/mono_ali_train/log/analyze_alignments.log
steps/align_si.sh: done aligning data.

===== TRI1 (first triphone pass) TRAINING =====

steps/train_deltas.sh --boost-silence 1.25 --cmd run.pl --mem 2G 2000 10000 data/train data/lang_nosp exp/mono_ali_train exp/tri1
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
WARNING (gmm-init-model[5.5.1009~1-e4940]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 1 with no stats; corresponding phone list: 6 7 8 9 10 
** The warnings above about 'no stats' generally mean you have phones **
** (or groups of phones) in your phone set that had no corresponding data. **
** You should probably figure out whether something went wrong, **
** or whether your data just doesn't happen to have examples of those **
** phones. **
steps/train_deltas.sh: converting alignments from exp/mono_ali_train to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang_nosp exp/tri1
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri1/log/analyze_alignments.log
3 warnings in exp/tri1/log/init_model.log
220 warnings in exp/tri1/log/align.*.*.log
1 warnings in exp/tri1/log/build_tree.log
127 warnings in exp/tri1/log/acc.*.*.log
34 warnings in exp/tri1/log/update.*.log
1 warnings in exp/tri1/log/questions.log
exp/tri1: nj=2 align prob=-97.30 over 15.30h [retry=0.4%, fail=0.0%] states=1584 gauss=10027 tree-impr=3.84
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri1

===== TRI1 (first triphone pass) DECODING =====

0 -0.044485
[info]: CLG not stochastic.
0.622451 -0.117788
HCLGa is not stochastic

===== TRI1 ALIGNMENT =====

steps/align_si.sh --nj 2 --cmd run.pl --mem 2G data/train data/lang_nosp exp/tri1 exp/tri1_ali_train
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train using model from exp/tri1, putting alignments in exp/tri1_ali_train
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang_nosp exp/tri1_ali_train
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri1_ali_train/log/analyze_alignments.log
steps/align_si.sh: done aligning data.

===== train an LDA+MLLT system =====

steps/train_lda_mllt.sh --cmd run.pl --mem 2G --splice-opts --left-context=3 --right-context=3 2500 15000 data/train data/lang_nosp exp/tri1_ali_train exp/tri2b
steps/train_lda_mllt.sh: Accumulating LDA statistics.
steps/train_lda_mllt.sh: Accumulating tree stats
steps/train_lda_mllt.sh: Getting questions for tree clustering.
steps/train_lda_mllt.sh: Building the tree
steps/train_lda_mllt.sh: Initializing the model
WARNING (gmm-init-model[5.5.1009~1-e4940]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 1 with no stats; corresponding phone list: 6 7 8 9 10 
This is a bad warning.
steps/train_lda_mllt.sh: Converting alignments from exp/tri1_ali_train to use current tree
steps/train_lda_mllt.sh: Compiling graphs of transcripts
Training pass 1
Training pass 2
steps/train_lda_mllt.sh: Estimating MLLT
Training pass 3
Training pass 4
steps/train_lda_mllt.sh: Estimating MLLT
Training pass 5
Training pass 6
steps/train_lda_mllt.sh: Estimating MLLT
Training pass 7
Training pass 8
Training pass 9
Training pass 10
Aligning data
Training pass 11
Training pass 12
steps/train_lda_mllt.sh: Estimating MLLT
Training pass 13
Training pass 14
Training pass 15
Training pass 16
Training pass 17
Training pass 18
Training pass 19
Training pass 20
Aligning data
Training pass 21
Training pass 22
Training pass 23
Training pass 24
Training pass 25
Training pass 26
Training pass 27
Training pass 28
Training pass 29
Training pass 30
Aligning data
Training pass 31
Training pass 32
Training pass 33
Training pass 34
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang_nosp exp/tri2b
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri2b/log/analyze_alignments.log
1 warnings in exp/tri2b/log/questions.log
1 warnings in exp/tri2b/log/build_tree.log
4 warnings in exp/tri2b/log/lda_acc.*.log
151 warnings in exp/tri2b/log/acc.*.*.log
11 warnings in exp/tri2b/log/init_model.log
263 warnings in exp/tri2b/log/align.*.*.log
35 warnings in exp/tri2b/log/update.*.log
exp/tri2b: nj=2 align prob=-45.35 over 15.30h [retry=0.4%, fail=0.0%] states=1920 gauss=15034 tree-impr=4.02 lda-sum=14.72 mllt:impr,logdet=0.92,1.31
steps/train_lda_mllt.sh: Done training system with LDA+MLLT features in exp/tri2b

===== Align utts using the tri2b model =====

steps/align_si.sh --nj 2 --cmd run.pl --mem 2G --use-graphs true data/train data/lang_nosp exp/tri2b exp/tri2b_ali_train
steps/align_si.sh: feature type is lda
steps/align_si.sh: aligning data in data/train using model from exp/tri2b, putting alignments in exp/tri2b_ali_train
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang_nosp exp/tri2b_ali_train
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri2b_ali_train/log/analyze_alignments.log
steps/align_si.sh: done aligning data.

===== Train tri3b, which is LDA+MLLT+SAT =====

steps/train_sat.sh --cmd run.pl --mem 2G 2500 15000 data/train data/lang_nosp exp/tri2b_ali_train exp/tri3b
steps/train_sat.sh: feature type is lda
steps/train_sat.sh: obtaining initial fMLLR transforms since not present in exp/tri2b_ali_train
steps/train_sat.sh: Accumulating tree stats
steps/train_sat.sh: Getting questions for tree clustering.
steps/train_sat.sh: Building the tree
steps/train_sat.sh: Initializing the model
WARNING (gmm-init-model[5.5.1009~1-e4940]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 1 with no stats; corresponding phone list: 6 7 8 9 10 
This is a bad warning.
steps/train_sat.sh: Converting alignments from exp/tri2b_ali_train to use current tree
steps/train_sat.sh: Compiling graphs of transcripts
Pass 1
Pass 2
Estimating fMLLR transforms
Pass 3
Pass 4
Estimating fMLLR transforms
Pass 5
Pass 6
Estimating fMLLR transforms
Pass 7
Pass 8
Pass 9
Pass 10
Aligning data
Pass 11
Pass 12
Estimating fMLLR transforms
Pass 13
Pass 14
Pass 15
Pass 16
Pass 17
Pass 18
Pass 19
Pass 20
Aligning data
Pass 21
Pass 22
Pass 23
Pass 24
Pass 25
Pass 26
Pass 27
Pass 28
Pass 29
Pass 30
Aligning data
Pass 31
Pass 32
Pass 33
Pass 34
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang_nosp exp/tri3b
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri3b/log/analyze_alignments.log
185 warnings in exp/tri3b/log/acc.*.*.log
1 warnings in exp/tri3b/log/est_alimdl.log
1 warnings in exp/tri3b/log/build_tree.log
4 warnings in exp/tri3b/log/init_model.log
307 warnings in exp/tri3b/log/align.*.*.log
1 warnings in exp/tri3b/log/questions.log
108 warnings in exp/tri3b/log/fmllr.*.*.log
37 warnings in exp/tri3b/log/update.*.log
steps/train_sat.sh: Likelihood evolution:
-48.3329 -48.2373 -47.9137 -47.6058 -46.7044 -46.0492 -45.6001 -45.3484 -45.1529 -44.5724 -44.327 -44.2322 -43.946 -43.832 -43.7312 -43.6496 -43.5785 -43.509 -43.4349 -43.2361 -43.1118 -43.053 -42.9983 -42.942 -42.8922 -42.8456 -42.8002 -42.7571 -42.7146 -42.6219 -42.5585 -42.5287 -42.5069 -42.4902 
exp/tri3b: nj=2 align prob=-45.93 over 15.30h [retry=0.5%, fail=0.0%] states=2016 gauss=15016 fmllr-impr=3.21 over 9.79h tree-impr=5.88
steps/train_sat.sh: done training SAT system in exp/tri3b

===== compute the pronunciation and silence probabilities =====

steps/get_prons.sh --cmd run.pl --mem 2G data/train data/lang_nosp exp/tri3b
steps/get_prons.sh: exp/tri3b/ali.1.gz exists, so starting from alignments.
steps/get_prons.sh: done writing prons to exp/tri3b/prons.*.gz, silence counts in 
steps/get_prons.sh: exp/tri3b/sil_counts_nowb.txt and pronunciation counts in 
steps/get_prons.sh: exp/tri3b/pron_counts.{int,txt}
steps/get_prons.sh: ... and also in exp/tri3b/pron_counts_nowb.txt
Checking data/local/dict_nosp/silence_phones.txt ...
--> reading data/local/dict_nosp/silence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/silence_phones.txt is OK

Checking data/local/dict_nosp/optional_silence.txt ...
--> reading data/local/dict_nosp/optional_silence.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/optional_silence.txt is OK

Checking data/local/dict_nosp/nonsilence_phones.txt ...
--> reading data/local/dict_nosp/nonsilence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/dict_nosp/lexicon.txt
--> reading data/local/dict_nosp/lexicon.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/lexicon.txt is OK

Checking data/local/dict_nosp/lexiconp.txt
--> reading data/local/dict_nosp/lexiconp.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/lexiconp.txt is OK

Checking lexicon pair data/local/dict_nosp/lexicon.txt and data/local/dict_nosp/lexiconp.txt
--> lexicon pair data/local/dict_nosp/lexicon.txt and data/local/dict_nosp/lexiconp.txt match

Checking data/local/dict_nosp/extra_questions.txt ...
--> data/local/dict_nosp/extra_questions.txt is empty (this is OK)
--> SUCCESS [validating dictionary directory data/local/dict_nosp]

utils/dict_dir_add_pronprobs.sh: normalizing pronprobs so maximum is 1 for each word.
utils/dict_dir_add_pronprobs.sh: produced dictionary directory with probabilities in data/local/dict/
utils/dict_dir_add_pronprobs.sh: validating data/local/dict ..
Checking data/local/dict/silence_phones.txt ...
--> reading data/local/dict/silence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/silence_phones.txt is OK

Checking data/local/dict/optional_silence.txt ...
--> reading data/local/dict/optional_silence.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/optional_silence.txt is OK

Checking data/local/dict/nonsilence_phones.txt ...
--> reading data/local/dict/nonsilence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/dict/lexicon.txt
--> reading data/local/dict/lexicon.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexicon.txt is OK

Checking data/local/dict/lexiconp.txt
--> reading data/local/dict/lexiconp.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexiconp.txt is OK

Checking data/local/dict/lexiconp_silprob.txt
--> reading data/local/dict/lexiconp_silprob.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexiconp_silprob.txt is OK

Checking lexicon pair data/local/dict/lexicon.txt and data/local/dict/lexiconp.txt
--> lexicon pair data/local/dict/lexicon.txt and data/local/dict/lexiconp.txt match

Checking lexicon pair data/local/dict/lexiconp.txt and data/local/dict/lexiconp_silprob.txt
--> lexicon pair data/local/dict/lexiconp.txt and data/local/dict/lexiconp_silprob.txt match

Checking data/local/dict/extra_questions.txt ...
--> data/local/dict/extra_questions.txt is empty (this is OK)
--> SUCCESS [validating dictionary directory data/local/dict]

Some low-probability prons include: 
# sort -k2,2 -n data/local/dict/lexiconp.txt  | head -n 8
ivez 0.0469799 I V E Z
reont 0.0588236 R A I N T
petra 0.0710527 P E R A
neuze 0.0714285 N EN N
bezañ 0.0722892 B EY OE
gwin 0.0810811 V I N
marteze 0.0810811 M A R S EH
ivez 0.100671 U W EH
utils/prepare_lang.sh data/local/dict <UNK> data/local/lang_tmp data/lang
Checking data/local/dict/silence_phones.txt ...
--> reading data/local/dict/silence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/silence_phones.txt is OK

Checking data/local/dict/optional_silence.txt ...
--> reading data/local/dict/optional_silence.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/optional_silence.txt is OK

Checking data/local/dict/nonsilence_phones.txt ...
--> reading data/local/dict/nonsilence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/dict/lexicon.txt
--> reading data/local/dict/lexicon.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexicon.txt is OK

Checking data/local/dict/lexiconp.txt
--> reading data/local/dict/lexiconp.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexiconp.txt is OK

Checking data/local/dict/lexiconp_silprob.txt
--> reading data/local/dict/lexiconp_silprob.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexiconp_silprob.txt is OK

Checking lexicon pair data/local/dict/lexicon.txt and data/local/dict/lexiconp.txt
--> lexicon pair data/local/dict/lexicon.txt and data/local/dict/lexiconp.txt match

Checking lexicon pair data/local/dict/lexiconp.txt and data/local/dict/lexiconp_silprob.txt
--> lexicon pair data/local/dict/lexiconp.txt and data/local/dict/lexiconp_silprob.txt match

Checking data/local/dict/extra_questions.txt ...
--> data/local/dict/extra_questions.txt is empty (this is OK)
--> SUCCESS [validating dictionary directory data/local/dict]

prepare_lang.sh: validating output directory
utils/validate_lang.pl data/lang
Checking existence of separator file
separator file data/lang/subword_separator.txt is empty or does not exist, deal in word case.
Checking data/lang/phones.txt ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang/phones.txt is OK

Checking words.txt: #0 ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> found no unexplainable phones in phones.txt

Checking data/lang/phones/context_indep.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.int corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.csl corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.{txt, int, csl} are OK

Checking data/lang/phones/nonsilence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 160 entry/entries in data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.int corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.csl corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang/phones/silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang/phones/silence.txt
--> data/lang/phones/silence.int corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.csl corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.{txt, int, csl} are OK

Checking data/lang/phones/optional_silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.int corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.csl corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang/phones/disambig.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 5 entry/entries in data/lang/phones/disambig.txt
--> data/lang/phones/disambig.int corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.csl corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.{txt, int, csl} are OK

Checking data/lang/phones/roots.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang/phones/roots.txt
--> data/lang/phones/roots.int corresponds to data/lang/phones/roots.txt
--> data/lang/phones/roots.{txt, int} are OK

Checking data/lang/phones/sets.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang/phones/sets.txt
--> data/lang/phones/sets.int corresponds to data/lang/phones/sets.txt
--> data/lang/phones/sets.{txt, int} are OK

Checking data/lang/phones/extra_questions.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 9 entry/entries in data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.int corresponds to data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.{txt, int} are OK

Checking data/lang/phones/word_boundary.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 175 entry/entries in data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.int corresponds to data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang/phones/disambig.txt has "#0" and "#1"
--> data/lang/phones/disambig.txt is OK

Checking topo ...

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang/phones/word_boundary.txt is OK

Checking word-level disambiguation symbols...
--> data/lang/phones/wdisambig.txt exists (newer prepare_lang.sh)
Checking word_boundary.int and disambig.int
--> generating a 79 word/subword sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 32 word/subword sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang/oov.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang/oov.txt
--> data/lang/oov.int corresponds to data/lang/oov.txt
--> data/lang/oov.{txt, int} are OK

--> data/lang/L.fst is olabel sorted
--> data/lang/L_disambig.fst is olabel sorted
--> SUCCESS [validating lang directory data/lang]
utils/validate_lang.pl data/lang
Checking existence of separator file
separator file data/lang/subword_separator.txt is empty or does not exist, deal in word case.
Checking data/lang/phones.txt ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang/phones.txt is OK

Checking words.txt: #0 ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> found no unexplainable phones in phones.txt

Checking data/lang/phones/context_indep.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.int corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.csl corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.{txt, int, csl} are OK

Checking data/lang/phones/nonsilence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 160 entry/entries in data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.int corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.csl corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang/phones/silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang/phones/silence.txt
--> data/lang/phones/silence.int corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.csl corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.{txt, int, csl} are OK

Checking data/lang/phones/optional_silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.int corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.csl corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang/phones/disambig.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 5 entry/entries in data/lang/phones/disambig.txt
--> data/lang/phones/disambig.int corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.csl corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.{txt, int, csl} are OK

Checking data/lang/phones/roots.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang/phones/roots.txt
--> data/lang/phones/roots.int corresponds to data/lang/phones/roots.txt
--> data/lang/phones/roots.{txt, int} are OK

Checking data/lang/phones/sets.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang/phones/sets.txt
--> data/lang/phones/sets.int corresponds to data/lang/phones/sets.txt
--> data/lang/phones/sets.{txt, int} are OK

Checking data/lang/phones/extra_questions.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 9 entry/entries in data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.int corresponds to data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.{txt, int} are OK

Checking data/lang/phones/word_boundary.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 175 entry/entries in data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.int corresponds to data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang/phones/disambig.txt has "#0" and "#1"
--> data/lang/phones/disambig.txt is OK

Checking topo ...

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang/phones/word_boundary.txt is OK

Checking word-level disambiguation symbols...
--> data/lang/phones/wdisambig.txt exists (newer prepare_lang.sh)
Checking word_boundary.int and disambig.int
--> generating a 25 word/subword sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 43 word/subword sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang/oov.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang/oov.txt
--> data/lang/oov.int corresponds to data/lang/oov.txt
--> data/lang/oov.{txt, int} are OK

--> data/lang/L.fst is olabel sorted
--> data/lang/L_disambig.fst is olabel sorted
--> SUCCESS [validating lang directory data/lang]
Checking data/local/dict/silence_phones.txt ...
--> reading data/local/dict/silence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/silence_phones.txt is OK

Checking data/local/dict/optional_silence.txt ...
--> reading data/local/dict/optional_silence.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/optional_silence.txt is OK

Checking data/local/dict/nonsilence_phones.txt ...
--> reading data/local/dict/nonsilence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/dict/lexicon.txt
--> reading data/local/dict/lexicon.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexicon.txt is OK

Checking data/local/dict/lexiconp.txt
--> reading data/local/dict/lexiconp.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexiconp.txt is OK

Checking data/local/dict/lexiconp_silprob.txt
--> reading data/local/dict/lexiconp_silprob.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexiconp_silprob.txt is OK

Checking lexicon pair data/local/dict/lexicon.txt and data/local/dict/lexiconp.txt
--> lexicon pair data/local/dict/lexicon.txt and data/local/dict/lexiconp.txt match

Checking lexicon pair data/local/dict/lexiconp.txt and data/local/dict/lexiconp_silprob.txt
--> lexicon pair data/local/dict/lexiconp.txt and data/local/dict/lexiconp_silprob.txt match

Checking data/local/dict/extra_questions.txt ...
--> data/local/dict/extra_questions.txt is empty (this is OK)
--> SUCCESS [validating dictionary directory data/local/dict]

******* format_lms **********
utils/validate_lang.pl data/lang_test_tgsmall
Checking existence of separator file
separator file data/lang_test_tgsmall/subword_separator.txt is empty or does not exist, deal in word case.
Checking data/lang_test_tgsmall/phones.txt ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang_test_tgsmall/phones.txt is OK

Checking words.txt: #0 ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang_test_tgsmall/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> found no unexplainable phones in phones.txt

Checking data/lang_test_tgsmall/phones/context_indep.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang_test_tgsmall/phones/context_indep.txt
--> data/lang_test_tgsmall/phones/context_indep.int corresponds to data/lang_test_tgsmall/phones/context_indep.txt
--> data/lang_test_tgsmall/phones/context_indep.csl corresponds to data/lang_test_tgsmall/phones/context_indep.txt
--> data/lang_test_tgsmall/phones/context_indep.{txt, int, csl} are OK

Checking data/lang_test_tgsmall/phones/nonsilence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 160 entry/entries in data/lang_test_tgsmall/phones/nonsilence.txt
--> data/lang_test_tgsmall/phones/nonsilence.int corresponds to data/lang_test_tgsmall/phones/nonsilence.txt
--> data/lang_test_tgsmall/phones/nonsilence.csl corresponds to data/lang_test_tgsmall/phones/nonsilence.txt
--> data/lang_test_tgsmall/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang_test_tgsmall/phones/silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang_test_tgsmall/phones/silence.txt
--> data/lang_test_tgsmall/phones/silence.int corresponds to data/lang_test_tgsmall/phones/silence.txt
--> data/lang_test_tgsmall/phones/silence.csl corresponds to data/lang_test_tgsmall/phones/silence.txt
--> data/lang_test_tgsmall/phones/silence.{txt, int, csl} are OK

Checking data/lang_test_tgsmall/phones/optional_silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang_test_tgsmall/phones/optional_silence.txt
--> data/lang_test_tgsmall/phones/optional_silence.int corresponds to data/lang_test_tgsmall/phones/optional_silence.txt
--> data/lang_test_tgsmall/phones/optional_silence.csl corresponds to data/lang_test_tgsmall/phones/optional_silence.txt
--> data/lang_test_tgsmall/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang_test_tgsmall/phones/disambig.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 5 entry/entries in data/lang_test_tgsmall/phones/disambig.txt
--> data/lang_test_tgsmall/phones/disambig.int corresponds to data/lang_test_tgsmall/phones/disambig.txt
--> data/lang_test_tgsmall/phones/disambig.csl corresponds to data/lang_test_tgsmall/phones/disambig.txt
--> data/lang_test_tgsmall/phones/disambig.{txt, int, csl} are OK

Checking data/lang_test_tgsmall/phones/roots.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang_test_tgsmall/phones/roots.txt
--> data/lang_test_tgsmall/phones/roots.int corresponds to data/lang_test_tgsmall/phones/roots.txt
--> data/lang_test_tgsmall/phones/roots.{txt, int} are OK

Checking data/lang_test_tgsmall/phones/sets.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang_test_tgsmall/phones/sets.txt
--> data/lang_test_tgsmall/phones/sets.int corresponds to data/lang_test_tgsmall/phones/sets.txt
--> data/lang_test_tgsmall/phones/sets.{txt, int} are OK

Checking data/lang_test_tgsmall/phones/extra_questions.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 9 entry/entries in data/lang_test_tgsmall/phones/extra_questions.txt
--> data/lang_test_tgsmall/phones/extra_questions.int corresponds to data/lang_test_tgsmall/phones/extra_questions.txt
--> data/lang_test_tgsmall/phones/extra_questions.{txt, int} are OK

Checking data/lang_test_tgsmall/phones/word_boundary.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 175 entry/entries in data/lang_test_tgsmall/phones/word_boundary.txt
--> data/lang_test_tgsmall/phones/word_boundary.int corresponds to data/lang_test_tgsmall/phones/word_boundary.txt
--> data/lang_test_tgsmall/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang_test_tgsmall/phones/optional_silence.txt
--> data/lang_test_tgsmall/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang_test_tgsmall/phones/disambig.txt has "#0" and "#1"
--> data/lang_test_tgsmall/phones/disambig.txt is OK

Checking topo ...

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang_test_tgsmall/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang_test_tgsmall/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang_test_tgsmall/phones/word_boundary.txt is OK

Checking word-level disambiguation symbols...
--> data/lang_test_tgsmall/phones/wdisambig.txt exists (newer prepare_lang.sh)
Checking word_boundary.int and disambig.int
--> generating a 53 word/subword sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 89 word/subword sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang_test_tgsmall/oov.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang_test_tgsmall/oov.txt
--> data/lang_test_tgsmall/oov.int corresponds to data/lang_test_tgsmall/oov.txt
--> data/lang_test_tgsmall/oov.{txt, int} are OK

--> data/lang_test_tgsmall/L.fst is olabel sorted
--> data/lang_test_tgsmall/L_disambig.fst is olabel sorted
--> data/lang_test_tgsmall/G.fst is ilabel sorted
--> data/lang_test_tgsmall/G.fst has 20268 states
--> utils/lang/check_g_properties.pl successfully validated data/lang_test_tgsmall/G.fst
--> utils/lang/check_g_properties.pl succeeded.
--> SUCCESS [validating lang directory data/lang_test_tgsmall]
utils/validate_lang.pl data/lang_test_tgmed
Checking existence of separator file
separator file data/lang_test_tgmed/subword_separator.txt is empty or does not exist, deal in word case.
Checking data/lang_test_tgmed/phones.txt ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang_test_tgmed/phones.txt is OK

Checking words.txt: #0 ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang_test_tgmed/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> found no unexplainable phones in phones.txt

Checking data/lang_test_tgmed/phones/context_indep.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang_test_tgmed/phones/context_indep.txt
--> data/lang_test_tgmed/phones/context_indep.int corresponds to data/lang_test_tgmed/phones/context_indep.txt
--> data/lang_test_tgmed/phones/context_indep.csl corresponds to data/lang_test_tgmed/phones/context_indep.txt
--> data/lang_test_tgmed/phones/context_indep.{txt, int, csl} are OK

Checking data/lang_test_tgmed/phones/nonsilence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 160 entry/entries in data/lang_test_tgmed/phones/nonsilence.txt
--> data/lang_test_tgmed/phones/nonsilence.int corresponds to data/lang_test_tgmed/phones/nonsilence.txt
--> data/lang_test_tgmed/phones/nonsilence.csl corresponds to data/lang_test_tgmed/phones/nonsilence.txt
--> data/lang_test_tgmed/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang_test_tgmed/phones/silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang_test_tgmed/phones/silence.txt
--> data/lang_test_tgmed/phones/silence.int corresponds to data/lang_test_tgmed/phones/silence.txt
--> data/lang_test_tgmed/phones/silence.csl corresponds to data/lang_test_tgmed/phones/silence.txt
--> data/lang_test_tgmed/phones/silence.{txt, int, csl} are OK

Checking data/lang_test_tgmed/phones/optional_silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang_test_tgmed/phones/optional_silence.txt
--> data/lang_test_tgmed/phones/optional_silence.int corresponds to data/lang_test_tgmed/phones/optional_silence.txt
--> data/lang_test_tgmed/phones/optional_silence.csl corresponds to data/lang_test_tgmed/phones/optional_silence.txt
--> data/lang_test_tgmed/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang_test_tgmed/phones/disambig.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 5 entry/entries in data/lang_test_tgmed/phones/disambig.txt
--> data/lang_test_tgmed/phones/disambig.int corresponds to data/lang_test_tgmed/phones/disambig.txt
--> data/lang_test_tgmed/phones/disambig.csl corresponds to data/lang_test_tgmed/phones/disambig.txt
--> data/lang_test_tgmed/phones/disambig.{txt, int, csl} are OK

Checking data/lang_test_tgmed/phones/roots.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang_test_tgmed/phones/roots.txt
--> data/lang_test_tgmed/phones/roots.int corresponds to data/lang_test_tgmed/phones/roots.txt
--> data/lang_test_tgmed/phones/roots.{txt, int} are OK

Checking data/lang_test_tgmed/phones/sets.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang_test_tgmed/phones/sets.txt
--> data/lang_test_tgmed/phones/sets.int corresponds to data/lang_test_tgmed/phones/sets.txt
--> data/lang_test_tgmed/phones/sets.{txt, int} are OK

Checking data/lang_test_tgmed/phones/extra_questions.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 9 entry/entries in data/lang_test_tgmed/phones/extra_questions.txt
--> data/lang_test_tgmed/phones/extra_questions.int corresponds to data/lang_test_tgmed/phones/extra_questions.txt
--> data/lang_test_tgmed/phones/extra_questions.{txt, int} are OK

Checking data/lang_test_tgmed/phones/word_boundary.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 175 entry/entries in data/lang_test_tgmed/phones/word_boundary.txt
--> data/lang_test_tgmed/phones/word_boundary.int corresponds to data/lang_test_tgmed/phones/word_boundary.txt
--> data/lang_test_tgmed/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang_test_tgmed/phones/optional_silence.txt
--> data/lang_test_tgmed/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang_test_tgmed/phones/disambig.txt has "#0" and "#1"
--> data/lang_test_tgmed/phones/disambig.txt is OK

Checking topo ...

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang_test_tgmed/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang_test_tgmed/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang_test_tgmed/phones/word_boundary.txt is OK

Checking word-level disambiguation symbols...
--> data/lang_test_tgmed/phones/wdisambig.txt exists (newer prepare_lang.sh)
Checking word_boundary.int and disambig.int
--> generating a 75 word/subword sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 47 word/subword sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang_test_tgmed/oov.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang_test_tgmed/oov.txt
--> data/lang_test_tgmed/oov.int corresponds to data/lang_test_tgmed/oov.txt
--> data/lang_test_tgmed/oov.{txt, int} are OK

--> data/lang_test_tgmed/L.fst is olabel sorted
--> data/lang_test_tgmed/L_disambig.fst is olabel sorted
--> data/lang_test_tgmed/G.fst is ilabel sorted
--> data/lang_test_tgmed/G.fst has 20268 states
--> utils/lang/check_g_properties.pl successfully validated data/lang_test_tgmed/G.fst
--> utils/lang/check_g_properties.pl succeeded.
--> SUCCESS [validating lang directory data/lang_test_tgmed]
******* build_const_arpa *****
****** align_fmllr ********
steps/align_fmllr.sh --nj 2 --cmd run.pl --mem 2G data/train data/lang exp/tri3b exp/tri3b_ali_train
steps/align_fmllr.sh: feature type is lda
steps/align_fmllr.sh: compiling training graphs
steps/align_fmllr.sh: aligning data in data/train using exp/tri3b/final.alimdl and speaker-independent features.
steps/align_fmllr.sh: computing fMLLR transforms
steps/align_fmllr.sh: doing final alignment.
steps/align_fmllr.sh: done aligning data.
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang exp/tri3b_ali_train
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri3b_ali_train/log/analyze_alignments.log
58 warnings in exp/tri3b_ali_train/log/align_pass2.*.log
20 warnings in exp/tri3b_ali_train/log/fmllr.*.log
51 warnings in exp/tri3b_ali_train/log/align_pass1.*.log

===== STAGE 9 =====
==== Test the tri3b system with the silprobs and pron-probs ====

-0.0917386 -0.0926803
[info]: LG not stochastic.
0 -0.0926803
[info]: CLG not stochastic.
0.612582 -0.270681
HCLGa is not stochastic
****** decode_fmllr.sh ******
steps/decode_fmllr.sh --nj 2 --cmd run.pl --mem 4G exp/tri3b/graph_tgsmall data/test exp/tri3b/decode_tgsmall_test
steps/decode.sh --scoring-opts  --num-threads 1 --skip-scoring false --acwt 0.083333 --nj 2 --cmd run.pl --mem 4G --beam 10.0 --model exp/tri3b/final.alimdl --max-active 2000 exp/tri3b/graph_tgsmall data/test exp/tri3b/decode_tgsmall_test.si
decode.sh: feature type is lda
steps/diagnostic/analyze_lats.sh --cmd run.pl --mem 4G exp/tri3b/graph_tgsmall exp/tri3b/decode_tgsmall_test.si
steps/diagnostic/analyze_lats.sh: see stats in exp/tri3b/decode_tgsmall_test.si/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,3,26) and mean=9.8
steps/diagnostic/analyze_lats.sh: see stats in exp/tri3b/decode_tgsmall_test.si/log/analyze_lattice_depth_stats.log
exp/tri3b/decode_tgsmall_test.si/wer_10
%WER 30.83 [ 279 / 905, 23 ins, 60 del, 196 sub ]
%SER 70.34 [ 83 / 118 ]
exp/tri3b/decode_tgsmall_test.si/wer_11
%WER 29.83 [ 270 / 905, 17 ins, 71 del, 182 sub ]
%SER 70.34 [ 83 / 118 ]
exp/tri3b/decode_tgsmall_test.si/wer_12
%WER 29.39 [ 266 / 905, 16 ins, 73 del, 177 sub ]
%SER 68.64 [ 81 / 118 ]
exp/tri3b/decode_tgsmall_test.si/wer_13
%WER 29.72 [ 269 / 905, 16 ins, 78 del, 175 sub ]
%SER 69.49 [ 82 / 118 ]
exp/tri3b/decode_tgsmall_test.si/wer_14
%WER 29.17 [ 264 / 905, 15 ins, 80 del, 169 sub ]
%SER 67.80 [ 80 / 118 ]
exp/tri3b/decode_tgsmall_test.si/wer_15
%WER 28.62 [ 259 / 905, 14 ins, 85 del, 160 sub ]
%SER 65.25 [ 77 / 118 ]
exp/tri3b/decode_tgsmall_test.si/wer_16
%WER 28.29 [ 256 / 905, 13 ins, 85 del, 158 sub ]
%SER 65.25 [ 77 / 118 ]
exp/tri3b/decode_tgsmall_test.si/wer_17
%WER 28.18 [ 255 / 905, 12 ins, 86 del, 157 sub ]
%SER 64.41 [ 76 / 118 ]
exp/tri3b/decode_tgsmall_test.si/wer_7
%WER 36.69 [ 332 / 905, 33 ins, 63 del, 236 sub ]
%SER 79.66 [ 94 / 118 ]
exp/tri3b/decode_tgsmall_test.si/wer_8
%WER 34.25 [ 310 / 905, 28 ins, 62 del, 220 sub ]
%SER 76.27 [ 90 / 118 ]
exp/tri3b/decode_tgsmall_test.si/wer_9
%WER 31.93 [ 289 / 905, 26 ins, 59 del, 204 sub ]
%SER 72.88 [ 86 / 118 ]
steps/decode_fmllr.sh: feature type is lda
steps/decode_fmllr.sh: getting first-pass fMLLR transforms.
steps/decode_fmllr.sh: doing main lattice generation phase
steps/decode_fmllr.sh: estimating fMLLR transforms a second time.
steps/decode_fmllr.sh: doing a final pass of acoustic rescoring.
steps/diagnostic/analyze_lats.sh --cmd run.pl --mem 4G exp/tri3b/graph_tgsmall exp/tri3b/decode_tgsmall_test
steps/diagnostic/analyze_lats.sh: see stats in exp/tri3b/decode_tgsmall_test/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,2,18) and mean=7.3
steps/diagnostic/analyze_lats.sh: see stats in exp/tri3b/decode_tgsmall_test/log/analyze_lattice_depth_stats.log
exp/tri3b/decode_tgsmall_test/wer_10
%WER 27.29 [ 247 / 905, 30 ins, 47 del, 170 sub ]
%SER 71.19 [ 84 / 118 ]
exp/tri3b/decode_tgsmall_test/wer_11
%WER 26.52 [ 240 / 905, 25 ins, 49 del, 166 sub ]
%SER 67.80 [ 80 / 118 ]
exp/tri3b/decode_tgsmall_test/wer_12
%WER 25.52 [ 231 / 905, 20 ins, 54 del, 157 sub ]
%SER 65.25 [ 77 / 118 ]
exp/tri3b/decode_tgsmall_test/wer_13
%WER 25.08 [ 227 / 905, 19 ins, 54 del, 154 sub ]
%SER 61.86 [ 73 / 118 ]
exp/tri3b/decode_tgsmall_test/wer_14
%WER 24.09 [ 218 / 905, 17 ins, 54 del, 147 sub ]
%SER 59.32 [ 70 / 118 ]
exp/tri3b/decode_tgsmall_test/wer_15
%WER 22.54 [ 204 / 905, 16 ins, 53 del, 135 sub ]
%SER 57.63 [ 68 / 118 ]
exp/tri3b/decode_tgsmall_test/wer_16
%WER 22.10 [ 200 / 905, 16 ins, 57 del, 127 sub ]
%SER 57.63 [ 68 / 118 ]
exp/tri3b/decode_tgsmall_test/wer_17
%WER 22.32 [ 202 / 905, 16 ins, 59 del, 127 sub ]
%SER 57.63 [ 68 / 118 ]
exp/tri3b/decode_tgsmall_test/wer_7
%WER 30.61 [ 277 / 905, 38 ins, 40 del, 199 sub ]
%SER 77.12 [ 91 / 118 ]
exp/tri3b/decode_tgsmall_test/wer_8
%WER 29.17 [ 264 / 905, 36 ins, 44 del, 184 sub ]
%SER 73.73 [ 87 / 118 ]
exp/tri3b/decode_tgsmall_test/wer_9
%WER 27.62 [ 250 / 905, 31 ins, 45 del, 174 sub ]
%SER 71.19 [ 84 / 118 ]
****** lmrescore.sh ******
steps/lmrescore.sh --cmd run.pl --mem 4G data/lang_test_tgsmall data/lang_test_tgmed data/test exp/tri3b/decode_tgsmall_test exp/tri3b/decode_tgmed_test
exp/tri3b/decode_tgmed_test/wer_10
%WER 27.51 [ 249 / 905, 30 ins, 47 del, 172 sub ]
%SER 71.19 [ 84 / 118 ]
exp/tri3b/decode_tgmed_test/wer_11
%WER 26.85 [ 243 / 905, 25 ins, 49 del, 169 sub ]
%SER 67.80 [ 80 / 118 ]
exp/tri3b/decode_tgmed_test/wer_12
%WER 25.86 [ 234 / 905, 20 ins, 53 del, 161 sub ]
%SER 65.25 [ 77 / 118 ]
exp/tri3b/decode_tgmed_test/wer_13
%WER 25.41 [ 230 / 905, 18 ins, 53 del, 159 sub ]
%SER 61.86 [ 73 / 118 ]
exp/tri3b/decode_tgmed_test/wer_14
%WER 24.53 [ 222 / 905, 16 ins, 54 del, 152 sub ]
%SER 60.17 [ 71 / 118 ]
exp/tri3b/decode_tgmed_test/wer_15
%WER 23.09 [ 209 / 905, 15 ins, 54 del, 140 sub ]
%SER 58.47 [ 69 / 118 ]
exp/tri3b/decode_tgmed_test/wer_16
%WER 22.98 [ 208 / 905, 15 ins, 58 del, 135 sub ]
%SER 59.32 [ 70 / 118 ]
exp/tri3b/decode_tgmed_test/wer_17
%WER 22.87 [ 207 / 905, 15 ins, 59 del, 133 sub ]
%SER 58.47 [ 69 / 118 ]
exp/tri3b/decode_tgmed_test/wer_7
%WER 30.61 [ 277 / 905, 38 ins, 41 del, 198 sub ]
%SER 77.12 [ 91 / 118 ]
exp/tri3b/decode_tgmed_test/wer_8
%WER 29.17 [ 264 / 905, 36 ins, 45 del, 183 sub ]
%SER 73.73 [ 87 / 118 ]
exp/tri3b/decode_tgmed_test/wer_9
%WER 27.62 [ 250 / 905, 30 ins, 45 del, 175 sub ]
%SER 71.19 [ 84 / 118 ]
****** lmrescore_const_arpa.sh ******
steps/lmrescore_const_arpa.sh --cmd run.pl --mem 4G data/lang_test_tgsmall data/lang_test_tglarge data/test exp/tri3b/decode_tgsmall_test exp/tri3b/decode_tglarge_test
exp/tri3b/decode_tglarge_test/wer_10
%WER 27.51 [ 249 / 905, 30 ins, 47 del, 172 sub ]
%SER 71.19 [ 84 / 118 ]
exp/tri3b/decode_tglarge_test/wer_11
%WER 26.85 [ 243 / 905, 25 ins, 49 del, 169 sub ]
%SER 67.80 [ 80 / 118 ]
exp/tri3b/decode_tglarge_test/wer_12
%WER 25.86 [ 234 / 905, 20 ins, 53 del, 161 sub ]
%SER 65.25 [ 77 / 118 ]
exp/tri3b/decode_tglarge_test/wer_13
%WER 25.52 [ 231 / 905, 18 ins, 53 del, 160 sub ]
%SER 62.71 [ 74 / 118 ]
exp/tri3b/decode_tglarge_test/wer_14
%WER 24.53 [ 222 / 905, 16 ins, 54 del, 152 sub ]
%SER 60.17 [ 71 / 118 ]
exp/tri3b/decode_tglarge_test/wer_15
%WER 23.09 [ 209 / 905, 15 ins, 54 del, 140 sub ]
%SER 58.47 [ 69 / 118 ]
exp/tri3b/decode_tglarge_test/wer_16
%WER 22.98 [ 208 / 905, 15 ins, 58 del, 135 sub ]
%SER 59.32 [ 70 / 118 ]
exp/tri3b/decode_tglarge_test/wer_17
%WER 22.87 [ 207 / 905, 15 ins, 59 del, 133 sub ]
%SER 58.47 [ 69 / 118 ]
exp/tri3b/decode_tglarge_test/wer_7
%WER 30.61 [ 277 / 905, 38 ins, 41 del, 198 sub ]
%SER 77.12 [ 91 / 118 ]
exp/tri3b/decode_tglarge_test/wer_8
%WER 29.17 [ 264 / 905, 36 ins, 45 del, 183 sub ]
%SER 73.73 [ 87 / 118 ]
exp/tri3b/decode_tglarge_test/wer_9
%WER 27.62 [ 250 / 905, 30 ins, 45 del, 175 sub ]
%SER 71.19 [ 84 / 118 ]

===== STAGE 10 =====
==== Train a chain model ====

local/chain/run_tdnn_1j_nogpu.sh 
local/nnet3/run_ivector_common.sh: preparing directory for low-resolution speed-perturbed data (for alignment)
fix_data_dir.sh: kept all 15740 utterances.
fix_data_dir.sh: old files are kept in data/train/.backup
utils/data/perturb_data_dir_speed_3way.sh: making sure the utt2dur and the reco2dur files are present
... in data/train, because obtaining it after speed-perturbing
... would be very slow, and you might need them.
utils/data/get_utt2dur.sh: data/train/utt2dur already exists with the expected length.  We won't recompute it.
utils/data/get_reco2dur.sh: obtaining durations from recordings
utils/data/get_reco2dur.sh: could not get recording lengths from sphere-file headers, using wav-to-duration
utils/data/get_reco2dur.sh: computed data/train/reco2dur
utils/data/perturb_data_dir_speed.sh: generated speed-perturbed version of data in data/train, in data/train_sp_speed0.9
fix_data_dir.sh: kept all 15740 utterances.
fix_data_dir.sh: old files are kept in data/train_sp_speed0.9/.backup
utils/validate_data_dir.sh: Successfully validated data-directory data/train_sp_speed0.9
utils/data/perturb_data_dir_speed.sh: generated speed-perturbed version of data in data/train, in data/train_sp_speed1.1
fix_data_dir.sh: kept all 15740 utterances.
fix_data_dir.sh: old files are kept in data/train_sp_speed1.1/.backup
utils/validate_data_dir.sh: Successfully validated data-directory data/train_sp_speed1.1
utils/data/combine_data.sh data/train_sp data/train data/train_sp_speed0.9 data/train_sp_speed1.1
utils/data/combine_data.sh: combined utt2uniq
utils/data/combine_data.sh: combined segments
utils/data/combine_data.sh: combined utt2spk
utils/data/combine_data.sh [info]: not combining utt2lang as it does not exist
utils/data/combine_data.sh: combined utt2dur
utils/data/combine_data.sh [info]: **not combining utt2num_frames as it does not exist everywhere**
utils/data/combine_data.sh: combined reco2dur
utils/data/combine_data.sh [info]: **not combining feats.scp as it does not exist everywhere**
utils/data/combine_data.sh: combined text
utils/data/combine_data.sh [info]: **not combining cmvn.scp as it does not exist everywhere**
utils/data/combine_data.sh [info]: not combining vad.scp as it does not exist
utils/data/combine_data.sh [info]: not combining reco2file_and_channel as it does not exist
utils/data/combine_data.sh: combined wav.scp
utils/data/combine_data.sh: combined spk2gender
fix_data_dir.sh: kept all 47220 utterances.
fix_data_dir.sh: old files are kept in data/train_sp/.backup
utils/data/perturb_data_dir_speed_3way.sh: generated 3-way speed-perturbed version of data in data/train, in data/train_sp
utils/validate_data_dir.sh: Successfully validated data-directory data/train_sp
local/nnet3/run_ivector_common.sh: making MFCC features for low-resolution speed-perturbed data
steps/make_mfcc.sh --cmd run.pl --mem 2G --nj 1 data/train_sp
utils/validate_data_dir.sh: Successfully validated data-directory data/train_sp
steps/make_mfcc.sh [info]: segments file exists: using that.
steps/make_mfcc.sh: Succeeded creating MFCC features for train_sp
steps/compute_cmvn_stats.sh data/train_sp
Succeeded creating CMVN stats for train_sp
fix_data_dir.sh: kept all 47220 utterances.
fix_data_dir.sh: old files are kept in data/train_sp/.backup
local/nnet3/run_ivector_common.sh: aligning with the perturbed low-resolution data
steps/align_fmllr.sh --nj 1 --cmd run.pl --mem 2G data/train_sp data/lang exp/tri3b exp/tri3b_ali_train_sp
steps/align_fmllr.sh: feature type is lda
steps/align_fmllr.sh: compiling training graphs
steps/align_fmllr.sh: aligning data in data/train_sp using exp/tri3b/final.alimdl and speaker-independent features.
steps/align_fmllr.sh: computing fMLLR transforms
steps/align_fmllr.sh: doing final alignment.
steps/align_fmllr.sh: done aligning data.
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang exp/tri3b_ali_train_sp
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri3b_ali_train_sp/log/analyze_alignments.log
184 warnings in exp/tri3b_ali_train_sp/log/align_pass1.*.log
60 warnings in exp/tri3b_ali_train_sp/log/fmllr.*.log
194 warnings in exp/tri3b_ali_train_sp/log/align_pass2.*.log
local/nnet3/run_ivector_common.sh: creating high-resolution MFCC features
utils/copy_data_dir.sh: copied data from data/train_sp to data/train_sp_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/train_sp_hires
utils/copy_data_dir.sh: copied data from data/test to data/test_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/test_hires
utils/data/perturb_data_dir_volume.sh: data/train_sp_hires/feats.scp exists; moving it to data/train_sp_hires/.backup/ as it wouldn't be valid any more.
utils/data/perturb_data_dir_volume.sh: added volume perturbation to the data in data/train_sp_hires
steps/make_mfcc.sh --nj 1 --mfcc-config conf/mfcc_hires.conf --cmd run.pl --mem 2G data/train_sp_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/train_sp_hires
steps/make_mfcc.sh [info]: segments file exists: using that.
steps/make_mfcc.sh: Succeeded creating MFCC features for train_sp_hires
steps/compute_cmvn_stats.sh data/train_sp_hires
Succeeded creating CMVN stats for train_sp_hires
fix_data_dir.sh: kept all 47220 utterances.
fix_data_dir.sh: old files are kept in data/train_sp_hires/.backup
steps/make_mfcc.sh --nj 1 --mfcc-config conf/mfcc_hires.conf --cmd run.pl --mem 2G data/test_hires
steps/make_mfcc.sh: moving data/test_hires/feats.scp to data/test_hires/.backup
utils/validate_data_dir.sh: Successfully validated data-directory data/test_hires
steps/make_mfcc.sh [info]: segments file exists: using that.
steps/make_mfcc.sh: Succeeded creating MFCC features for test_hires
steps/compute_cmvn_stats.sh data/test_hires
Succeeded creating CMVN stats for test_hires
fix_data_dir.sh: kept all 118 utterances.
fix_data_dir.sh: old files are kept in data/test_hires/.backup
local/nnet3/run_ivector_common.sh: computing a subset of data to train the diagonal UBM.
utils/data/subset_data_dir.sh: reducing #utt from 47220 to 11805
local/nnet3/run_ivector_common.sh: computing a PCA transform from the hires data.
steps/online/nnet2/get_pca_transform.sh --cmd run.pl --mem 2G --splice-opts --left-context=3 --right-context=3 --max-utts 10000 --subsample 2 exp/nnet3/diag_ubm/train_sp_hires_subset exp/nnet3/pca_transform
Done estimating PCA transform in exp/nnet3/pca_transform
local/nnet3/run_ivector_common.sh: training the diagonal UBM.
steps/online/nnet2/train_diag_ubm.sh --cmd run.pl --mem 2G --nj 1 --num-frames 700000 --num-threads 8 exp/nnet3/diag_ubm/train_sp_hires_subset 512 exp/nnet3/pca_transform exp/nnet3/diag_ubm
steps/online/nnet2/train_diag_ubm.sh: Directory exp/nnet3/diag_ubm already exists. Backing up diagonal UBM in exp/nnet3/diag_ubm/backup.lzo
steps/online/nnet2/train_diag_ubm.sh: initializing model from E-M in memory, 
steps/online/nnet2/train_diag_ubm.sh: starting from 256 Gaussians, reaching 512;
steps/online/nnet2/train_diag_ubm.sh: for 20 iterations, using at most 700000 frames of data
Getting Gaussian-selection info
steps/online/nnet2/train_diag_ubm.sh: will train for 4 iterations, in parallel over
steps/online/nnet2/train_diag_ubm.sh: 1 machines, parallelized with 'run.pl --mem 2G'
steps/online/nnet2/train_diag_ubm.sh: Training pass 0
steps/online/nnet2/train_diag_ubm.sh: Training pass 1
steps/online/nnet2/train_diag_ubm.sh: Training pass 2
steps/online/nnet2/train_diag_ubm.sh: Training pass 3
local/nnet3/run_ivector_common.sh: training the iVector extractor
steps/online/nnet2/train_ivector_extractor.sh --cmd run.pl --mem 2G --nj 1 --num-threads 4 --num-processes 2 --online-cmvn-iextractor false data/train_sp_hires exp/nnet3/diag_ubm exp/nnet3/extractor
steps/online/nnet2/train_ivector_extractor.sh: doing Gaussian selection and posterior computation
Accumulating stats (pass 0)
Summing accs (pass 0)
Updating model (pass 0)
Accumulating stats (pass 1)
Summing accs (pass 1)
Updating model (pass 1)
Accumulating stats (pass 2)
Summing accs (pass 2)
Updating model (pass 2)
Accumulating stats (pass 3)
Summing accs (pass 3)
Updating model (pass 3)
Accumulating stats (pass 4)
Summing accs (pass 4)
Updating model (pass 4)
Accumulating stats (pass 5)
Summing accs (pass 5)
Updating model (pass 5)
Accumulating stats (pass 6)
Summing accs (pass 6)
Updating model (pass 6)
Accumulating stats (pass 7)
Summing accs (pass 7)
Updating model (pass 7)
Accumulating stats (pass 8)
Summing accs (pass 8)
Updating model (pass 8)
Accumulating stats (pass 9)
Summing accs (pass 9)
Updating model (pass 9)
utils/data/modify_speaker_info.sh: copied data from data/train_sp_hires to exp/nnet3/ivectors_train_sp_hires/train_sp_hires_max2, number of speakers changed from 615 to 23760
utils/validate_data_dir.sh: Successfully validated data-directory exp/nnet3/ivectors_train_sp_hires/train_sp_hires_max2
steps/online/nnet2/extract_ivectors_online.sh --cmd run.pl --mem 2G --nj 1 exp/nnet3/ivectors_train_sp_hires/train_sp_hires_max2 exp/nnet3/extractor exp/nnet3/ivectors_train_sp_hires
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/nnet3/ivectors_train_sp_hires using the extractor in exp/nnet3/extractor.
steps/online/nnet2/extract_ivectors_online.sh --cmd run.pl --mem 2G --nj 1 data/test_hires exp/nnet3/extractor exp/nnet3/ivectors_test_hires
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/nnet3/ivectors_test_hires using the extractor in exp/nnet3/extractor.
local/chain/run_tdnn_1j_nogpu.sh: creating lang directory data/lang_chain with chain-type topology

====== STAGE 11 ======
steps/align_fmllr_lats.sh --nj 2 --cmd run.pl --mem 2G data/train_sp data/lang exp/tri3b exp/chain/tri3b_train_sp_lats
steps/align_fmllr_lats.sh: feature type is lda
steps/align_fmllr_lats.sh: compiling training graphs
steps/align_fmllr_lats.sh: aligning data in data/train_sp using exp/tri3b/final.alimdl and speaker-independent features.
steps/align_fmllr_lats.sh: computing fMLLR transforms
steps/align_fmllr_lats.sh: generating lattices containing alternate pronunciations.
steps/align_fmllr_lats.sh: done generating lattices from training transcripts.
11 warnings in exp/chain/tri3b_train_sp_lats/log/generate_lattices.*.log
60 warnings in exp/chain/tri3b_train_sp_lats/log/fmllr.*.log
190 warnings in exp/chain/tri3b_train_sp_lats/log/align_pass1.*.log

====== STAGE 12 ======
steps/nnet3/chain/build_tree.sh --frame-subsampling-factor 3 --context-opts --context-width=2 --central-position=1 --cmd run.pl --mem 2G 3500 data/train_sp data/lang_chain exp/tri3b_ali_train_sp exp/chain/tree_sp
steps/nnet3/chain/build_tree.sh: feature type is lda
steps/nnet3/chain/build_tree.sh: Using transforms from exp/tri3b_ali_train_sp
steps/nnet3/chain/build_tree.sh: Initializing monophone model (for alignment conversion, in case topology changed)
steps/nnet3/chain/build_tree.sh: Accumulating tree stats
steps/nnet3/chain/build_tree.sh: Getting questions for tree clustering.
steps/nnet3/chain/build_tree.sh: Building the tree
steps/nnet3/chain/build_tree.sh: Initializing the model
WARNING (gmm-init-model[5.5.1009~1-e4940]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 1 with no stats; corresponding phone list: 6 7 8 9 10 
This is a bad warning.
steps/nnet3/chain/build_tree.sh: Converting alignments from exp/tri3b_ali_train_sp to use current tree
steps/nnet3/chain/build_tree.sh: Done building tree

====== STAGE 13 ======
local/chain/run_tdnn_1j_nogpu.sh: creating neural net configs using the xconfig parser

====== STAGE 14 ======
steps/nnet3/chain/get_egs.sh --frames-overlap-per-eg 0 --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir exp/nnet3/ivectors_train_sp_hires --left-context 30 --right-context 30 --left-context-initial -1 --right-context-final -1 --left-tolerance 5 --right-tolerance 5 --frame-subsampling-factor 3 --alignment-subsampling-factor 3 --stage 0 --frames-per-iter 3000000 --frames-per-eg 140,100,160 --srand 0 data/train_sp_hires exp/chain/tdnn1j_sp exp/chain/tri3b_train_sp_lats exp/chain/tdnn1j_sp/egs
steps/nnet3/chain/get_egs.sh: File data/train_sp_hires/utt2uniq exists, so ensuring the hold-out set includes all perturbed versions of the same source utterance.
steps/nnet3/chain/get_egs.sh: Holding out 300 utterances in validation set and 300 in training diagnostic set, out of total 47220.
steps/nnet3/chain/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/chain/tdnn1j_sp/egs/.nodelete
steps/nnet3/chain/get_egs.sh: feature type is raw, with 'apply-cmvn'
steps/nnet3/chain/get_egs.sh: working out number of frames of training data
steps/nnet3/chain/get_egs.sh: working out feature dim
steps/nnet3/chain/get_egs.sh: creating 6 archives, each with 17439 egs, with
steps/nnet3/chain/get_egs.sh:   140,100,160 labels per example, and (left,right) context = (30,30)
steps/nnet3/chain/get_egs.sh: Getting validation and training subset examples in background.
steps/nnet3/chain/get_egs.sh: Generating training examples on disk
steps/nnet3/chain/get_egs.sh: Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/chain/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/chain/get_egs.sh: Removing temporary archives, alignments and lattices
steps/nnet3/chain/get_egs.sh: Finished preparing training examples
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/chain/tdnn1j_sp/egs
exp/chain/tdnn1j_sp: num-iters=180 nj=2..2 num-params=5.2M dim=40+100->2344 combine=-0.116->-0.110 (over 6) xent:train/valid[119,179]=(-2.28,-2.09/-2.34,-2.17) logprob:train/valid[119,179]=(-0.120,-0.104/-0.140,-0.127)
steps/nnet3/chain/train.py --stage=-10 --cmd=run.pl --mem 4G --feat.online-ivector-dir=exp/nnet3/ivectors_train_sp_hires --feat.cmvn-opts=--norm-means=false --norm-vars=false --chain.xent-regularize 0.1 --chain.leaky-hmm-coefficient=0.1 --chain.l2-regularize=0.0 --chain.apply-deriv-weights=false --chain.lm-opts=--num-extra-lm-states=2000 --trainer.add-option=--optimization.memory-compression-level=2 --trainer.srand=0 --trainer.max-param-change=2.0 --trainer.num-epochs=20 --trainer.frames-per-iter=3000000 --trainer.optimization.num-jobs-initial=2 --trainer.optimization.num-jobs-final=2 --trainer.optimization.initial-effective-lrate=0.002 --trainer.optimization.final-effective-lrate=0.0002 --trainer.num-chunk-per-minibatch=128,64 --egs.chunk-width=140,100,160 --egs.dir= --egs.opts=--frames-overlap-per-eg 0 --cleanup.remove-egs=true --use-gpu=false --reporting.email= --feat-dir=data/train_sp_hires --tree-dir=exp/chain/tree_sp --lat-dir=exp/chain/tri3b_train_sp_lats --dir=exp/chain/tdnn1j_sp
['steps/nnet3/chain/train.py', '--stage=-10', '--cmd=run.pl --mem 4G', '--feat.online-ivector-dir=exp/nnet3/ivectors_train_sp_hires', '--feat.cmvn-opts=--norm-means=false --norm-vars=false', '--chain.xent-regularize', '0.1', '--chain.leaky-hmm-coefficient=0.1', '--chain.l2-regularize=0.0', '--chain.apply-deriv-weights=false', '--chain.lm-opts=--num-extra-lm-states=2000', '--trainer.add-option=--optimization.memory-compression-level=2', '--trainer.srand=0', '--trainer.max-param-change=2.0', '--trainer.num-epochs=20', '--trainer.frames-per-iter=3000000', '--trainer.optimization.num-jobs-initial=2', '--trainer.optimization.num-jobs-final=2', '--trainer.optimization.initial-effective-lrate=0.002', '--trainer.optimization.final-effective-lrate=0.0002', '--trainer.num-chunk-per-minibatch=128,64', '--egs.chunk-width=140,100,160', '--egs.dir=', '--egs.opts=--frames-overlap-per-eg 0', '--cleanup.remove-egs=true', '--use-gpu=false', '--reporting.email=', '--feat-dir=data/train_sp_hires', '--tree-dir=exp/chain/tree_sp', '--lat-dir=exp/chain/tri3b_train_sp_lats', '--dir=exp/chain/tdnn1j_sp']

====== STAGE 15 ======
-0.0917386 -0.0926803
[info]: CLG not stochastic.
0.545057 -0.354642
HCLGa is not stochastic
0.454642 -0.193059
[info]: final HCLG is not stochastic.

====== STAGE 16 ======
steps/nnet3/decode.sh --acwt 1.0 --post-decode-acwt 10.0 --frames-per-chunk 140 --nj 6 --cmd run.pl --mem 4G --num-threads 4 --online-ivector-dir exp/nnet3/ivectors_test_hires exp/chain/tree_sp/graph_tgsmall data/test_hires exp/chain/tdnn1j_sp/decode_tgsmall_test
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --mem 4G --iter final exp/chain/tree_sp/graph_tgsmall exp/chain/tdnn1j_sp/decode_tgsmall_test
steps/diagnostic/analyze_lats.sh: see stats in exp/chain/tdnn1j_sp/decode_tgsmall_test/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,4,62) and mean=43.5
steps/diagnostic/analyze_lats.sh: see stats in exp/chain/tdnn1j_sp/decode_tgsmall_test/log/analyze_lattice_depth_stats.log
score best paths
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_10
%WER 14.25 [ 129 / 905, 12 ins, 31 del, 86 sub ]
%SER 43.22 [ 51 / 118 ]
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_11
%WER 13.81 [ 125 / 905, 11 ins, 30 del, 84 sub ]
%SER 44.07 [ 52 / 118 ]
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_12
%WER 13.59 [ 123 / 905, 11 ins, 31 del, 81 sub ]
%SER 44.92 [ 53 / 118 ]
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_13
%WER 12.60 [ 114 / 905, 10 ins, 30 del, 74 sub ]
%SER 43.22 [ 51 / 118 ]
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_14
%WER 12.15 [ 110 / 905, 7 ins, 29 del, 74 sub ]
%SER 41.53 [ 49 / 118 ]
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_15
%WER 14.25 [ 129 / 905, 10 ins, 34 del, 85 sub ]
%SER 45.76 [ 54 / 118 ]
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_16
%WER 14.25 [ 129 / 905, 10 ins, 36 del, 83 sub ]
%SER 44.92 [ 53 / 118 ]
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_17
%WER 14.48 [ 131 / 905, 11 ins, 37 del, 83 sub ]
%SER 44.92 [ 53 / 118 ]
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_7
%WER 16.35 [ 148 / 905, 21 ins, 27 del, 100 sub ]
%SER 44.07 [ 52 / 118 ]
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_8
%WER 15.47 [ 140 / 905, 17 ins, 25 del, 98 sub ]
%SER 44.07 [ 52 / 118 ]
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_9
%WER 14.36 [ 130 / 905, 14 ins, 27 del, 89 sub ]
%SER 42.37 [ 50 / 118 ]
score confidence and timing with sclite
Decoding done.
steps/lmrescore_const_arpa.sh --cmd run.pl --mem 4G data/lang_test_tgsmall data/lang_test_tglarge data/test_hires exp/chain/tdnn1j_sp/decode_tgsmall_test exp/chain/tdnn1j_sp/decode_tglarge_test
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_10
%WER 13.81 [ 125 / 905, 12 ins, 29 del, 84 sub ]
%SER 41.53 [ 49 / 118 ]
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_11
%WER 13.48 [ 122 / 905, 11 ins, 28 del, 83 sub ]
%SER 42.37 [ 50 / 118 ]
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_12
%WER 13.15 [ 119 / 905, 11 ins, 30 del, 78 sub ]
%SER 43.22 [ 51 / 118 ]
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_13
%WER 12.49 [ 113 / 905, 8 ins, 31 del, 74 sub ]
%SER 43.22 [ 51 / 118 ]
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_14
%WER 12.60 [ 114 / 905, 7 ins, 31 del, 76 sub ]
%SER 42.37 [ 50 / 118 ]
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_15
%WER 14.14 [ 128 / 905, 8 ins, 37 del, 83 sub ]
%SER 44.07 [ 52 / 118 ]
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_16
%WER 13.92 [ 126 / 905, 8 ins, 36 del, 82 sub ]
%SER 43.22 [ 51 / 118 ]
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_17
%WER 13.92 [ 126 / 905, 8 ins, 37 del, 81 sub ]
%SER 43.22 [ 51 / 118 ]
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_7
%WER 16.69 [ 151 / 905, 20 ins, 27 del, 104 sub ]
%SER 45.76 [ 54 / 118 ]
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_8
%WER 15.47 [ 140 / 905, 17 ins, 25 del, 98 sub ]
%SER 43.22 [ 51 / 118 ]
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_9
%WER 14.14 [ 128 / 905, 14 ins, 26 del, 88 sub ]
%SER 41.53 [ 49 / 118 ]

====== STAGE 17 ======
steps/online/nnet3/prepare_online_decoding.sh --mfcc-config conf/mfcc_hires.conf data/lang_chain exp/nnet3/extractor exp/chain/tdnn1j_sp exp/chain/tdnn1j_sp_online
steps/online/nnet3/prepare_online_decoding.sh: preparing configuration files in /home/gweltaz/STT/kaldi/egs/bzg/exp/chain/tdnn1j_sp_online/conf
steps/online/nnet3/prepare_online_decoding.sh: created config file /home/gweltaz/STT/kaldi/egs/bzg/exp/chain/tdnn1j_sp_online/conf/online.conf
steps/online/nnet3/decode.sh --acwt 1.0 --post-decode-acwt 10.0 --nj 6 --cmd run.pl --mem 4G exp/chain/tree_sp/graph_tgsmall data/test exp/chain/tdnn1j_sp_online/decode_tgsmall_test
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_10
%WER 14.36 [ 130 / 905, 12 ins, 31 del, 87 sub ]
%SER 43.22 [ 51 / 118 ]
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_11
%WER 14.03 [ 127 / 905, 11 ins, 31 del, 85 sub ]
%SER 44.07 [ 52 / 118 ]
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_12
%WER 13.70 [ 124 / 905, 11 ins, 32 del, 81 sub ]
%SER 44.92 [ 53 / 118 ]
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_13
%WER 13.26 [ 120 / 905, 10 ins, 32 del, 78 sub ]
%SER 44.92 [ 53 / 118 ]
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_14
%WER 12.38 [ 112 / 905, 7 ins, 29 del, 76 sub ]
%SER 42.37 [ 50 / 118 ]
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_15
%WER 13.70 [ 124 / 905, 10 ins, 32 del, 82 sub ]
%SER 44.92 [ 53 / 118 ]
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_16
%WER 14.25 [ 129 / 905, 10 ins, 36 del, 83 sub ]
%SER 44.92 [ 53 / 118 ]
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_17
%WER 14.36 [ 130 / 905, 11 ins, 37 del, 82 sub ]
%SER 44.92 [ 53 / 118 ]
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_7
%WER 16.24 [ 147 / 905, 20 ins, 27 del, 100 sub ]
%SER 44.07 [ 52 / 118 ]
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_8
%WER 15.47 [ 140 / 905, 17 ins, 26 del, 97 sub ]
%SER 42.37 [ 50 / 118 ]
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_9
%WER 14.48 [ 131 / 905, 13 ins, 28 del, 90 sub ]
%SER 42.37 [ 50 / 118 ]
steps/lmrescore_const_arpa.sh --cmd run.pl --mem 4G data/lang_test_tgsmall data/lang_test_tglarge data/test_hires exp/chain/tdnn1j_sp_online/decode_tgsmall_test exp/chain/tdnn1j_sp_online/decode_tglarge_test
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_10
%WER 13.92 [ 126 / 905, 12 ins, 29 del, 85 sub ]
%SER 41.53 [ 49 / 118 ]
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_11
%WER 13.70 [ 124 / 905, 11 ins, 29 del, 84 sub ]
%SER 42.37 [ 50 / 118 ]
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_12
%WER 13.48 [ 122 / 905, 11 ins, 31 del, 80 sub ]
%SER 44.07 [ 52 / 118 ]
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_13
%WER 13.04 [ 118 / 905, 8 ins, 32 del, 78 sub ]
%SER 44.07 [ 52 / 118 ]
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_14
%WER 12.93 [ 117 / 905, 7 ins, 32 del, 78 sub ]
%SER 43.22 [ 51 / 118 ]
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_15
%WER 13.59 [ 123 / 905, 8 ins, 35 del, 80 sub ]
%SER 43.22 [ 51 / 118 ]
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_16
%WER 13.92 [ 126 / 905, 8 ins, 36 del, 82 sub ]
%SER 43.22 [ 51 / 118 ]
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_17
%WER 14.03 [ 127 / 905, 9 ins, 37 del, 81 sub ]
%SER 43.22 [ 51 / 118 ]
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_7
%WER 16.69 [ 151 / 905, 20 ins, 27 del, 104 sub ]
%SER 45.76 [ 54 / 118 ]
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_8
%WER 15.91 [ 144 / 905, 17 ins, 27 del, 100 sub ]
%SER 43.22 [ 51 / 118 ]
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_9
%WER 14.25 [ 129 / 905, 13 ins, 27 del, 89 sub ]
%SER 41.53 [ 49 / 118 ]

===== run.sh script is finished =====

